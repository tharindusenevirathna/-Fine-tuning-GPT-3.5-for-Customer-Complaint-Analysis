{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome To The Notebook"
      ],
      "metadata": {
        "id": "2AqPte8bet51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1 - Set up the project environment"
      ],
      "metadata": {
        "id": "1Rp80dTGpsDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.7.2 python-dotenv"
      ],
      "metadata": {
        "id": "lx4wV2MIUJ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing modules"
      ],
      "metadata": {
        "id": "qypdUNULptjB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFmEp0r5T2eI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os, time\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Modules are imported.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the OpenAI API:\n",
        "\n",
        "* Prepare a .env file to store the OpenAI API key.\n",
        "* Uploading the .env file to our colab environment\n",
        "* Load the API key and setup the API"
      ],
      "metadata": {
        "id": "XfVAcV_XqDja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv('apikey.env.txt')\n",
        "\n",
        "APIKEY=os.getenv('APIKEY')"
      ],
      "metadata": {
        "id": "rbXC4QM4qCBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating OpenAI Client"
      ],
      "metadata": {
        "id": "rWxipGQIpxH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client=OpenAI(\n",
        "    api_key=APIKEY\n",
        ")\n",
        "client"
      ],
      "metadata": {
        "id": "nHj-RaA5p0WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 - Prepare the training data"
      ],
      "metadata": {
        "id": "0r2XnfwnqTCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the provided `Customer Complaints.csv`\n",
        "\n"
      ],
      "metadata": {
        "id": "-_Alc-CyuHmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=pd.read_csv('Customer Complaints.csv')\n",
        "training_data"
      ],
      "metadata": {
        "id": "jan2OKk5qW1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the Complaints records to json**\n",
        "\n",
        "To be able to use the data for the fine-tuning purpose, we first need to convert each row of the dataframe into the following format:\n",
        "\n",
        "<pre>\n",
        "<code>\n",
        "{\n",
        "  <span style=\"color: blue;\">\"messages\"</span>: [\n",
        "    {\n",
        "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"system\"</span>,\n",
        "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">Providing context about the user's prompt.\n",
        "                  It may include information about the task,\n",
        "                  instructions, or background details relevant\n",
        "                  to the conversation.</span>\"\n",
        "    },\n",
        "    {\n",
        "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"user\"</span>,\n",
        "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">the prompt or input provided by the user,\n",
        "                  which typically initiates the conversation with the assistant.</span>\"\n",
        "    },\n",
        "    {\n",
        "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"assistant\"</span>,\n",
        "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">The desired response or output generated by\n",
        "                  the assistant in response to the user's prompt.</span>\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "</code>\n",
        "</pre>\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "uIK863G-qvMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a method that get's a row of the dataframe and convert it into the json format"
      ],
      "metadata": {
        "id": "fWVCfuvRjdXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_as_json(row):\n",
        "\n",
        "  system_content = \"\"\"\n",
        "      Given a customer complaint text, extract and return the following information in json (dict) format:\n",
        "      - Topic: The product/department that the customer has a complaint about.\n",
        "      - Problem: A two or three-word description of what exactly the problem is.\n",
        "      - Customer_Dissatisfaction_Index: is a number between 0 and 100 showing\n",
        "             how angry the customer is about the problem.\n",
        "  \"\"\"\n",
        "\n",
        "  formatted_data = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_content},\n",
        "            {\"role\": \"user\", \"content\": row.Complaints},\n",
        "            {\"role\": \"assistant\", \"content\": row.Details}\n",
        "        ]\n",
        "      }\n",
        "\n",
        "  with open(\"training_data.json\", \"a\") as json_file:\n",
        "        json.dump(formatted_data, json_file)\n",
        "        json_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "-tHnvRamq5NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use of this method to generate the `training_data.json`"
      ],
      "metadata": {
        "id": "K3haPgzI-ClF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in training_data.iterrows():\n",
        "  save_as_json(row)"
      ],
      "metadata": {
        "id": "LNOMxwSX8dE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3 - Fine-tune GPT 3.5 based on our training data"
      ],
      "metadata": {
        "id": "Jo9HFdW0jput"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import the json file we prepared as our training data"
      ],
      "metadata": {
        "id": "h4TMhzSNj4hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file=client.files.create(\n",
        "    file=open('training_data.json','rb'),\n",
        "    purpose='fine-tune',\n",
        "\n",
        ")\n",
        "data_file"
      ],
      "metadata": {
        "id": "ExJ2cRU5-XtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Fine Tuning Job"
      ],
      "metadata": {
        "id": "TiBcO3I0kIU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning_job=client.fine_tuning_jobs.create(\n",
        "    training_file=data_file.id,\n",
        "    model='gpt-3.5-turbo',\n",
        "    hyperparameters={\n",
        "        \"n_epochs\":'auto'\n",
        "\n",
        "    }\n",
        ")\n",
        "fine_tuning_job"
      ],
      "metadata": {
        "id": "BXJB348zkMSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's retrieve the state of the fine-tune"
      ],
      "metadata": {
        "id": "u7XWcO_7kzY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  time.sleep(2)\n",
        "  retrieved_jobs=client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\n",
        "  status=retrieved_jobs.status\n",
        "  print(status)\n",
        "\n",
        "  if status==\"succeeded\":\n",
        "    print(\"The job is done!\")\n",
        "    break\n"
      ],
      "metadata": {
        "id": "hpbHjWu3AS4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4 - Evaluate model"
      ],
      "metadata": {
        "id": "4XB-sFc3kO4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's retrieve the event messages to check out the learning process of our fine-tuning job."
      ],
      "metadata": {
        "id": "p_3bNsW3k_eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events=list(client.fine_tuning_jobs.list_events(fine_tuning_job_id=retrieved_jobs.id,limit=100).data)\n",
        "for e in events:\n",
        "  print(e.message)\n",
        "\n"
      ],
      "metadata": {
        "id": "O2bif68aIEGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract the training loss in each learning step"
      ],
      "metadata": {
        "id": "Pe3jUJJjyeO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps=[]\n",
        "train_loss=[]\n",
        "\n",
        "for e in events:\n",
        "  if(e.data):\n",
        "    steps.append(e.data['step'])\n",
        "    train_loss.append(e.data['train_loss'])\n",
        "\n",
        "print(steps)\n",
        "print(train_loss)\n"
      ],
      "metadata": {
        "id": "oqhDoVBNzW_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a line chart to visualize the train_loss in each step"
      ],
      "metadata": {
        "id": "iiiJIUuq2W4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(steps,train_loss,maker='o',linestyle='-')"
      ],
      "metadata": {
        "id": "EMRvEd-F2bLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5 - Deploy our model"
      ],
      "metadata": {
        "id": "8lGyZnvk25q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at `retrieved_jobs` again"
      ],
      "metadata": {
        "id": "EYljL-wH42ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myLLM=retrieved_jobs.fine_tune_model\n",
        "print(myLLM)"
      ],
      "metadata": {
        "id": "q4ChDCWo3H85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a method to extract information from a given user complaint using a specific LLM and return the results."
      ],
      "metadata": {
        "id": "nLLfuwC4-h9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_details(user_complaint, model_name):\n",
        "    \"\"\"\n",
        "    This function extracts information from a given user complaint using a specific LLM (Large Language Model).\n",
        "\n",
        "    Parameters:\n",
        "    user_complaint (str): The text of the user's complaint.\n",
        "    model_name (str): The name of the specific LLM model to use for extraction.\n",
        "    \"\"\"\n",
        "\n",
        "    system_content = \"\"\"\n",
        "        Given a customer complaint text, extract and return the following information in JSON (dict) format:\n",
        "        - Topic\n",
        "        - Problem\n",
        "        - Customer_Dissatisfaction_Index\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a response using the specified model and the user's complaint\n",
        "    response = client.chat.completions.create(\n",
        "        model = model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_content},  # System content explaining the expected output\n",
        "            {\"role\": \"user\", \"content\": user_complaint}  # User's complaint passed as content\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Return the content of the generated response\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "P3_99_Hf5CV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use our fine-tuned model to extract the details for the following user complaint:\n",
        "\n",
        "*TV channels keep disappearing from my subscription! What's going on? Extremely annoyed with this service!*"
      ],
      "metadata": {
        "id": "zE_O2zAwplof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complaint=\"TV channels keep disappearing from my subscription! What's going on? Extremely annoyed with this service!\"\n",
        "extract_details(complaint,myLLM)"
      ],
      "metadata": {
        "id": "vD1dEjnzWTuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our `GPT-4` model with the same user complaint"
      ],
      "metadata": {
        "id": "LJNgLZoS6-gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_details(complaint,'gpt-4')"
      ],
      "metadata": {
        "id": "G2XBuw0N47AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try for the following complaint:\n",
        "\n",
        "*Line is down! It is really annoying!*"
      ],
      "metadata": {
        "id": "J3xZBAUitpVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complaint=\"Line is down! It is really annoying!\"\n",
        "extract_details(complaint,myLLM)"
      ],
      "metadata": {
        "id": "I3O6HzK_ttZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compare the results from GPT-4"
      ],
      "metadata": {
        "id": "W4zeLRZfuNmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_details(complaint,'gpt-4')"
      ],
      "metadata": {
        "id": "6ubUkjXXuQ8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our model, which is trained on our dataset, provides better answers compared to GPT-4. Our model is fine-tuned based on our data and is familiar with the different edge cases and the context of our dataset."
      ],
      "metadata": {
        "id": "YvqSymjWueXu"
      }
    }
  ]
}